---
title: "Projet - Répartition de la population française"
author: "Bouillon Baptiste"
output: pdf_document
---

\setlength\parindent{50pt}


\newpage
```{r setup,echo=FALSE,message=FALSE,warning=FALSE}
# options(Encoding="UTF-8")
# rmarkdown::render('C:/Users/Baptiste/Desktop/Rendu_Baptiste_markdown.Rmd', encoding = 'UTF-8')
```

```{r libraries & traitements, echo=FALSE, message=FALSE, warning=FALSE}

library(dplyr)
library(FactoMineR)
library(ggplot2)
library(stringr)
library(neuralnet)

```

```{r fonctions, echo=FALSE, message=FALSE, warning=FALSE}
# Recup.pire.coef : fonction qui rend le coeficient avec la p-value la plus petite parmis un ensemble de coeficients d'une régression linéaire multiple
# @ parmas : 
#   data.summary : un summary d'un lm
# @return :
#   return : le pire coeficient
Recup.pire.coef <- function(data.summary){
  # on supprime tous les coefficients avec une p-value supérieure à 0.05
  sum_model <- data.summary[data.summary$`Pr(>|t|)`>0.05,]
  # et on récupère le nom des coefficients
  retour <- rownames(sum_model)
  if(length(retour)==0){ # si tous les coefficients ont une p-value inférieure à 0.05 ...
    # on récupère le coefficient avec la p-value la plus grande
    sum_model <- data.summary[order(data.summary$`Pr(>|t|)`),]
    retour <- rownames(sum_model[nrow(sum_model),])
  }
  return(retour)
}
# Recup.pire.coef : fonction qui rend le coeficient avec la p-value la plus petite parmis un ensemble de coeficients d'une regression logistique
# @ parmas : 
#   data.summary : un summary d'un lm
# @return :
#   return : le pire coeficient
Recup.pire.coef_log <- function(data.summary){
  
  # on supprime tous les coefficients avec une p-value supérieure à 0.05
  sum_model <- data.summary[data.summary$`Pr(>|z|)`>0.05,]
  # et on récupère le nom des coefficients
  retour <- rownames(sum_model)
  if(length(retour)==0){ # si tous les coefficients ont une p-value inférieure à 0.05 ...
    # on récupère le coefficient avec la p-value la plus grande
    sum_model <- data.summary[order(data.summary$`Pr(>|z|)`),]
    retour <- rownames(sum_model[nrow(sum_model),])
  }
  return(retour)
}

logistique <- function(XX,BB){
  # dim(XX) dim(BB)
  score <- XX %*% BB
  return(1/(1+exp(-(score))))
}
```

```{r fonction_A, echo = FALSE}
Evolution_Pop <- function(dep,DF){
  cols <- c(names(DF[[dep]]))[3:13]
  cols <- cols[-6]
  
  par(xpd=TRUE, mar=c(8,4,4,3))
  plot(1, type = 'n',xlim = c(1995,2015), ylim = c(0,100000), xlab = 'Année', ylab = 'Population')
  
  for(i in 1:length(cols)){
    DEPARTEMENT <- ts(c(DF[[dep]][,cols[i]]),start = 1995, end = 2015)
    lines(DEPARTEMENT, col = i)
  }
  
  legend('bottomright', inset = c(-0.06, -0.45),legend=cols, col = seq(1:length(cols)), lty = 1, xpd = NA)
}

Repartition <- function(dep, DF, annee){
  
  DATA <- DF[[dep]]
  cols <- c(names(DATA))[3:13]
  cols <- cols[-6]
  data <- DATA[which(DATA$Annee==annee),cols]
  data <- unlist(data, use.names=FALSE)
  
  df <- data.frame(
    Categorie = cols,
    value = data
  )
  
  
  
  
  # camembert plot
    pie<- ggplot(df, aes(x="", y=value, fill=Categorie))+
    geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0)+
    geom_text(aes(x = c(1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3,1.3,1.3,1.5), 
                y = rev(c(0, cumsum(value)[-length(value)])), 
                label=paste(Categorie,"\n",round(value/sum(value)*100,2), "%")))+
      ggtitle(paste(dep, annee, sep = ", "))+
      theme(panel.background = element_blank(),
            panel.grid.major= element_blank(), 
            panel.grid.minor = element_blank(), 
            axis.text.x = element_blank(), 
            axis.text.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.ticks.x = element_blank(),
            axis.title.y = element_blank(),
            axis.title.x = element_blank(),
            legend.position="left",
            legend.text=element_text(size=10),
            legend.title=element_text(size=14),
            plot.title = element_text(color="Black", size=14, face="bold"))
    
  pie
}
```

```{r import_A, echo = FALSE}
DATA <- read.csv("../PREDIRE.csv",sep=";",header=T)

DF <- list()

for(dep in unique(DATA$Lieu)){
  DF[[dep]] <- as.data.frame(DATA[which(DATA$Lieu==dep),])
}

```

```{r importation, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

PREDICTEUR <- read.csv("../DATA_ALL2.csv",sep=";",header=T)
PREDICTRICE <-read.csv("../PREDIRE.csv",sep=";",header=T)


PREDICTEUR2 <- select(PREDICTEUR,-Annee)
PREDICTRICE2 <- select(PREDICTRICE,-Annee)

# PREDICTEUR.mean <- aggregate(.~Lieu,data=PREDICTEUR2,FUN=mean)
# PREDICTRICE.mean <- aggregate(.~Lieu,data=PREDICTRICE2,FUN=mean)
# 
# PREDICTEUR.ACP <- select(PREDICTEUR.mean,-Lieu)
# PREDICTRICE.ACP <- select(PREDICTRICE.mean,-Lieu)

index1995 <- rownames(PREDICTEUR[PREDICTEUR["Annee"]==1995,])
PREDICTEUR.ACP1 <- select(PREDICTEUR[index1995,],-Annee,-Lieu)
PREDICTRICE.ACP1 <- select(PREDICTRICE[index1995,],-Annee,-Lieu)

index2005 <- rownames(PREDICTEUR[PREDICTEUR["Annee"]==2005,])
PREDICTEUR.ACP2 <- select(PREDICTEUR[index2005,],-Annee,-Lieu)
PREDICTRICE.ACP2 <- select(PREDICTRICE[index2005,],-Annee,-Lieu)

index2015 <- rownames(PREDICTEUR[PREDICTEUR["Annee"]==2015,])
PREDICTEUR.ACP3 <- select(PREDICTEUR[index2015,],-Annee,-Lieu)
PREDICTRICE.ACP3 <- select(PREDICTRICE[index2015,],-Annee,-Lieu)

PREDICTEUR2 <- select(PREDICTEUR2,-Lieu)
PREDICTRICE2 <- select(PREDICTRICE2,-Lieu)
```

```{r, echo = FALSE}
Evolution_Pop <- function(dep,DF){
  cols <- c(names(DF[[dep]]))[3:13]
  cols <- cols[-6]
  
  par(xpd=TRUE, mar=c(8,4,4,3))
  plot(1, type = 'n',xlim = c(1995,2015), ylim = c(0,100000), xlab = 'Année', ylab = 'Population')
  
  for(i in 1:length(cols)){
    DEPARTEMENT <- ts(c(DF[[dep]][,cols[i]]),start = 1995, end = 2015)
    lines(DEPARTEMENT, col = i)
  }
  
  legend('bottomright', inset = c(-0.06, -0.45),legend=cols, col = seq(1:length(cols)), lty = 1, xpd = NA)
}

Repartition <- function(dep, DF, annee){
  
  DATA <- DF[[dep]]
  cols <- c(names(DATA))[3:13]
  cols <- cols[-6]
  data <- DATA[which(DATA$Annee==annee),cols]
  data <- unlist(data, use.names=FALSE)
  
  df <- data.frame(
    Categorie = cols,
    value = data
  )
  
  
  
  
  # camembert plot
    pie<- ggplot(df, aes(x="", y=value, fill=Categorie))+
    geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0)+
    geom_text(aes(x = c(1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3,1.3,1.3,1.5), 
                y = rev(c(0, cumsum(value)[-length(value)])), 
                label=paste(Categorie,"\n",round(value/sum(value)*100,2), "%")))+
      ggtitle(paste(dep, annee, sep = ", "))+
      theme(panel.background = element_blank(),
            panel.grid.major= element_blank(), 
            panel.grid.minor = element_blank(), 
            axis.text.x = element_blank(), 
            axis.text.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.ticks.x = element_blank(),
            axis.title.y = element_blank(),
            axis.title.x = element_blank(),
            legend.position="left",
            legend.text=element_text(size=10),
            legend.title=element_text(size=14),
            plot.title = element_text(color="Black", size=14, face="bold"))
    
  pie
}
```

```{r, echo = FALSE}
DATA <- read.csv("../PREDIRE.csv",sep=";",header=T)

DF <- list()

for(dep in unique(DATA$Lieu)){
  DF[[dep]] <- as.data.frame(DATA[which(DATA$Lieu==dep),])
}

```


\newpage
##Classification des départements via les caractéristiques territoriales naturelles et artificielles



<p style="text-align:justify;">Nous commençons par faire une CAH sur toutes nos variables prédictrices afin d'observer les similitudes et dissimilitudes des différents départements étudiés. Nous ferons des CAH en 1995, 2005 et 2015 afin d'observer l'évolution des différents départements sur la période étudiée.
</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ALL <- cbind(PREDICTEUR[,-1], PREDICTRICE[-c(1,2)])
ALL <- aggregate(.~Lieu, FUN = mean, data = ALL)
rownames(ALL) <- ALL$Lieu
ALL <- ALL[,-1]
ALL <- scale(ALL)
dAll <- dist(ALL[,1:(ncol(ALL)-11)])
CAHAll <- hclust(dAll)
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
inertie <- sort(CAHAll$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(5, 9), inertie[c(5, 9)], col = c("red3", "green3"), cex = 2, lwd = 3)
```

<p style="text-align:justify;">Pour commencer, il faut observer sur l'évolution de l'inertie résiduelle le nombre optimal de classes. Pour cela, nous allons chercher les différents coudes sur le graphique ci-dessus. Nous observons deux coudes susceptibles de signifier un bon nombre de classes, représentés par les cercles rouge et vert.
</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHAll, main = "Classification Ascendante Hiérarchique de la moyenne des départements sur toute la période")
rect.hclust(CAHAll, k = 5, border = "red3")
rect.hclust(CAHAll, k = 9, border = "green3")
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
groupesAll <- cutree(CAHAll, k = 9)
ALL <- cbind(PREDICTEUR[,-1], PREDICTRICE[-c(1,2)])
ALL <- aggregate(.~Lieu, FUN = mean, data = ALL)
rownames(ALL) <- ALL$Lieu
ALL <- ALL[,-1]
AllGps <- as.data.frame(cbind(groupesAll, ALL))
MoyenneAll <- colMeans(AllGps)
for( i in 1:max(groupesAll)){
  
  DFi <- AllGps[which(AllGps$groupesAll==i),]
  GroupeI <- aggregate(.~groupesAll, data = DFi, FUN = mean)
  MoyenneAll<- rbind(MoyenneAll, GroupeI)
  
}
#print(MoyenneAll)
```

<p style="text-align:justify;">Lors de la création de classes, il est important de les nommer afin de prouver qu'elles représentent quelque chose et que ce quelque chose est compréhensible.</p>


<p style="text-align:justify;">La première classe regroupe les régions montagneuses des Alpes en France. Elle est caractérisée par beaucoup de pluie. Peut-être à cause des montagnes qui bloquent les nuages. Les départements la composant possèdent très peu d'éolienne et de photovoltaïque mais beaucoup de barrages. Ils possèdent aussi énormément d'espaces protégés.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==1),])
```

<p style="text-align:justify;">Le deuxième groupe représente la majorité. Des départements, ni trop urbains, ni trop ruraux.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==2),])
```

<p style="text-align:justify;">Le troisième groupe regroupe la majorité des régions plutôt rurales, pauvres et relativement peu peuplées du centre de la France, la diagonale du vide.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==3),])
```

<p style="text-align:justify;">Une quatrième classe regroupe le Var, l'Hérault et les Alpes-Maritimes. Il s'agit des départements côtiers de méditerranée. Ils sont composés de villes assez actives : Toulon, Nice et Montpellier, ainsi que de grands espaces naturels.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==4),])
```

<p style="text-align:justify;">Le cinquième groupe représente les Bouches du Rhône. Il s'agit d'un département côtier, urbain et rural à la fois grâce à ses grands espaces naturels. De plus, ce département possède une grande zone portuaire ainsi que de nombreuses zones inondables. Son coté maritime peut être une forte explication de son exclusion du groupe composé de Lyon et de la région parisienne. D'un autre côté, l'importance de la zone urbaine l'a fortement éloigné du groupe des départements méditerranéens.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==5),])
```

<p style="text-align:justify;">le sixièmre groupe, composé des départements de la région parisienne et du Rhône, département de la ville de Lyon, est caractérisé par de grandes zones urbaines.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==6),])
```

<p style="text-align:justify;">Dans le septième groupe, la Gironde se retrouve toute seule. Il s'agit d'un grand département, possédant beaucoup de zones maritimes, agricoles, et beaucoup d'eau douce.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==7),])
```

<p style="text-align:justify;">La huitième classe contient les départements du nord de la France possédant de grands ports en eaux profondes (Le Havre). Il s'agit de départements froids, et avec un fort taux de chômage.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==8),])
```

<p style="text-align:justify;">Le dernier groupe, le neuvième, n'est composé que de Paris. Un département ville d'une très petite superficie et unique en France. C'est le département avec la plus grande activité.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesAll==9),])
```

<p style="text-align:justify;">On effectue la même analyse, mais cette fois-ci pour les données de 1995, 2005 et 2015 afin d'observer les rapprochements et éloignements des différents départements les uns des autres.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}

ALL <- cbind(PREDICTEUR[,], PREDICTRICE[-c(1,2)])
ALL <- ALL[which(ALL$Annee == 1995),2:130]
rownames(ALL) <- ALL$Lieu
ALL <- ALL[,-1]
ALL <- scale(ALL)
dAll <- dist(ALL[,1:128])
CAHAll <- hclust(dAll)
inertie <- sort(CAHAll$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(5, 9), inertie[c(5, 9)], col = c("red3", "green3"), cex = 2, lwd = 3)
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHAll, main = "Classification Ascendante Hiérarchique des départements en 1995")
groupesAll <- cutree(CAHAll, k = 9)
rect.hclust(CAHAll, k = 5, border = "red3")
rect.hclust(CAHAll, k = 9, border = "green3")
```

<p style="text-align:justify;">En 1995, la classification nous permet de séparer certains départements du groupe contenant la majorité du territoire. On observait déjà l'isolement de Paris, des Bouches du Rhône et de la Gironde. Il en était de même pour la région parisienne et Lyon qui forment un groupe de petits départements urbains. On observe un autre groupe composé des territoires relativement développés, avec de grandes zones urbaines quant aux autres et de petits départements par rapport à la majorité. On observe aussi une séparation du Nord et du Pas de Calais de la majorité. Ces départements se rapprochent plus de la région parisienne que de la majorité, ce que l'on pourrait expliquer par l'appartenance de ces territoires aux anciennes riches provinces des Flandres. Cependant, aujourd'hui, il s'agit plus de territoires pauvres très urbains, avec un taux de chômage élevé en comparaison du reste de la France. Encore une fois, on remarque que les Alpes française, leurs grandes zones protégées, ainsi que leur faible urbanisation sont séparées des autres départements. En 1995, on observe également le groupe constitué de la Lozère et des Alpes de Hautes Provences. Ces départements se rapprochent du groupe alpin. Cependant, la faible altitude et l'absence quasi-totale d'urbanisation de ces territoires, les séparent de ce groupe.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}

ALL <- cbind(PREDICTEUR[,], PREDICTRICE[-c(1,2)])
ALL <- ALL[which(ALL$Annee == 2005),2:130]
rownames(ALL) <- ALL$Lieu
ALL <- ALL[,-1]
ALL <- scale(ALL)
dAll <- dist(ALL[,1:128])
CAHAll <- hclust(dAll)
inertie <- sort(CAHAll$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(4, 7, 10), inertie[c(4, 7, 10)], col = c("red3", "green3", "blue3"), cex = 2, lwd = 3)

```

<p style="text-align:justify;">Sur ce graphique, la séparation des classes semble plus difficile. On observe 3 coudes distincts pouvant chacun être un nombre intéressant de groupes.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHAll, main = "Classification Ascendante Hiérarchique des départements en 2005")
groupesAll <- cutree(CAHAll, k = 5)
rect.hclust(CAHAll, k = 4, border = "red3")
rect.hclust(CAHAll, k = 7, border = "green3")
rect.hclust(CAHAll, k = 10, border = "blue3")
```

<p style="text-align:justify;">L'avantage de la classification ascendante hiérarchique réside dans le choix du nombre de classe. En effet, on peut passer facilement d'une à deux classes sans changer drastiquement la composition des classes. Ici, on va se focaliser sur les classes bleues. Encore et toujours, on se retrouve avec nos trois départements isolés. Paris, les Bouches du Rhône et la Gironde. Cette fois-ci, on observe un autre département en train de se séparer des autres : La Loire-Atlantique. D'un côté, ce département se rapproche des départements côtiers et très actifs du côté maritime, avec des ports importants comme le Havre, Dunkerque ou calais. Ce département s'est fortement éloigné des autres durant les 10 années séparant 1995 et 2005. Comme en 1995, on retrouve le groupe constitué de la région parisienne et de la ville de Lyon, ainsi que le groupes des Alpes française. En 2005, on notera l'apparition du groupe des départements actif et naturels méditerranéens (Var, Hérault et Alpes Maritimes).</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}

ALL <- cbind(PREDICTEUR[,], PREDICTRICE[-c(1,2)])
ALL <- ALL[which(ALL$Annee == 2015),2:130]
rownames(ALL) <- ALL$Lieu
ALL <- ALL[,-1]
ALL <- scale(ALL)
dAll <- dist(ALL[,1:128])
CAHAll <- hclust(dAll)
inertie <- sort(CAHAll$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(4, 8), inertie[c(4, 8)], col = c("red3", "green3", "blue3"), cex = 2, lwd = 3)

```

<p style="text-align:justify;">Même si 6 classes paraitraient plus adaptées, au vu du graphique ci-dessus, 8 classes permettent un meilleur découpage des zones.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHAll, main = "Classification Ascendante Hiérarchique des départements en 2015")
groupesAll <- cutree(CAHAll, k = 5)
rect.hclust(CAHAll, k = 4, border = "red3")
rect.hclust(CAHAll, k = 8, border = "green3")
```

<p style="text-align:justify;">Ainsi, en analysant cette classification, on se rend compte que la Loire-Atlantique a finalement rejoint les grands ports du nord de la France, et que ce groupe tend à rejoindre Bordeaux. On notera également la disparition du groupe constitué des départements méditerranéens. Pour ce qui est du groupe très urbain de la région parisienne et du Rhône, on remarque l'apparition des Alpes Maritimes. On peut expliquer cela par un fort développement urbain de ce département, notamment sur ses côtes. Les autres départements du groupe méditerranéen (Var, Hérault), se sont rapprochés des autres zones côtières du sud de la France. On finira en observant l'agrandissement du groupe regroupant les départements alpins, qui contient désormais de nombreux départements montagneux du sud de la France.</p>

<p style="text-align:justify;">On essaie par la suite de trouver quels sont les départements similaires en répartition de population.</p>

\newpage
##Classification des départements par la répartition de leur population



```{r, echo = FALSE, fig.height=12, fig.width=18}
repartition <- aggregate(.~Lieu, data = PREDICTRICE, FUN = mean)
row.names(repartition) <- repartition$Lieu
repartition <- repartition[,-1]

#Génération des pourcentages : 

repartition <- repartition/repartition$Population_Francaise_Totale

repartition <- repartition[,-6]
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
dRepartition <- dist(repartition)
CAHRepartition <- hclust(dRepartition)
inertie <- sort(CAHRepartition$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(6, 8), inertie[c(6, 8)], col = c("red3", "green3"), cex = 2, lwd = 3)
```

<p style="text-align:justify;">D'après le graphique de l'inertie résiduelle, il semblerait que 8 classes soient optimales pour notre classification.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHRepartition, main = "CAH de la répartition de la population des départements moyennés sur la période"  )
groupesrepartition <- cutree(CAHRepartition, k = 5)
rect.hclust(CAHRepartition, k = 6, border = "red3")
rect.hclust(CAHRepartition, k = 8, border = "green3")
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
repartition <- PREDICTRICE[which(PREDICTRICE$Annee == 1995),2:13]
row.names(repartition) <- repartition$Lieu
repartition <- repartition[,-1]

#Génération des pourcentages : 

repartition <- repartition/repartition$Population_Francaise_Totale

repartition <- repartition[,-6]
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
inertie <- sort(CAHRepartition$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(5,8), inertie[c(5,8)], col = c("red3", "green3"), cex = 2, lwd = 3)
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
dRepartition <- dist(repartition)
CAHRepartition <- hclust(dRepartition)
plot(CAHRepartition, main = "CAH de la répartition de la population des départements en 1995"  )
rect.hclust(CAHRepartition, k = 5, border = "red3")
rect.hclust(CAHRepartition, k = 8, border = "green3")
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
groupesRep <- cutree(CAHRepartition, k = 8)
ALL <- repartition
AllGps <- as.data.frame(cbind(groupesRep, ALL))
MoyenneRep <- colMeans(AllGps)
for( i in 1:max(groupesRep)){
  
  DFi <- AllGps[which(AllGps$groupesRep==i),]
  GroupeI <- aggregate(.~groupesRep, data = DFi, FUN = mean)
  MoyenneRep<- rbind(MoyenneRep, GroupeI)
  
}
#print(MoyenneRep)
```

<p style="text-align:justify;">Notre premier groupe est caractérisé par une population plus jeune que la moyenne nationnale.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 1
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

<p style="text-align:justify;">Les deuxième et troisième groupes sont tous deux très proches. Ils possèdent une population plus vielle que la moyenne française. Cependant, le groupe 2 est légèrement plus vieux.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 2
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 3
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

<p style="text-align:justify;">Ici avec le quatrième groupe, nous avons le groupe de départements représentant le mieux la moyenne nationale en répartition de population.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 4
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

<p style="text-align:justify;">Ce groupe est composé de départements très actifs et riches de région parisienne (Hauts de Seine, Val de Marne), et de deux autres départements actifs avec des grandes villes (Strasbourg et Toulouse). Il s'agit de départements avec peu de personnes âgées et une population jeune. Cependant, contrairement à Paris, il y a un nombre d'enfants proche de la moyenne nationale.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 5
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

<p style="text-align:justify;">La répartition de la population dans la Creuse est assez atypique. Ce département a la plus faible proportion d'actifs, ce qui est compensé par une proportion de seniors deux fois supérieure au reste de la France. De plus, avec Paris, il s'agit de l'un des départements avec le moins d'enfants en proportion.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 6
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

<p style="text-align:justify;">Ce groupe est composé des zones défavorisées la région parisienne. Contrairement à la classification précédente, où l'on s'attardait sur les caractéristiques des départements (urbanisation, terrain.), le département du Rhône, ne fait pas parti de ce groupe. Cette zone est notamment caractérisée par une population très jeune. C'est le groupe possédant le taux de senior le plus faible, et le taux d'enfants le plus élevé.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 7
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

<p style="text-align:justify;">Le fameux groupe ne contenant que Paris lors de la classification sur les variables explicatives se retrouve encore ici. Paris est un département unique en France. Il s'agit d'une zone totalement urbanisée, minuscule et extrêmement peuplée. De plus, c'est là-bas que se situe une énorme partie de l'activité française. C'est une région extrêmement dynamique, caractérisée par une population de jeunes actifs (plus de 36% de la population âgée de 20 à 40 ans et 25% âgée de 40 à 60 ans). Il n'y a pas beaucoup d'enfants, comme dans la Creuse. Ce département est toutefois dans la moyenne française concernant les seniors.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 8
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
Repartition("PARIS", DF, 1995)
```

<p style="text-align:justify;">Nous noterons par ailleurs que pour tous les départements, il y a plus d'hommes que de femmes chez les jeunes jusqu'à la tranche des 40 à 60 ans. Mais qu'au-delà, il y a plus de femmes que d'hommes. Au total, pour la somme de toutes les tranches d'âges, il y a plus de femmes que d'hommes.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
repartition <- PREDICTRICE[which(PREDICTRICE$Annee == 2005),2:13]
row.names(repartition) <- repartition$Lieu
repartition <- repartition[,-1]

#Génération des pourcentages : 

repartition <- repartition/repartition$Population_Francaise_Totale

repartition <- repartition[,-6]
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
dRepartition <- dist(repartition)
CAHRepartition <- hclust(dRepartition)
inertie <- sort(CAHRepartition$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(5,8), inertie[c(5,8)], col = c("red3", "green3"), cex = 2, lwd = 3)
```

<p style="text-align:justify;">Le point vert se situe au même nombre de classes que pour 1995. Nous allons rester sur ce nombre de classes afin de rester en cohérence avec les analyses précédentes.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHRepartition, main = "CAH de la répartition de la population des départements en 2005"  )
rect.hclust(CAHRepartition, k = 5, border = "red3")
rect.hclust(CAHRepartition, k = 8, border = "green3")
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
groupesRep <- cutree(CAHRepartition, k = 8)
ALL <- repartition
AllGps <- as.data.frame(cbind(groupesRep, ALL))
MoyenneRep <- colMeans(AllGps)
for( i in 1:max(groupesRep)){
  
  DFi <- AllGps[which(AllGps$groupesRep==i),]
  GroupeI <- aggregate(.~groupesRep, data = DFi, FUN = mean)
  MoyenneRep<- rbind(MoyenneRep, GroupeI)
  
}
print(t(MoyenneRep))
```

<p style="text-align:justify;">Tout d'abord, on remarque que Paris n'a pas beaucoup évolué entre 1995 et 2005. On y retrouve encore une fois une population jeune et sans enfants. Le reste de la région Parisienne reste globalement inchangé. L'autre département solitaire de 1995, la Creuse, s'est quant à lui rapproché de certains départements, les départements les moins peuplés de France, qui se caractérisent par conséquent par une forte proportion de seniors. Ces départements sont très éloignés des autres sur le plan de la répartition de la population.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
rownames(AllGps[which(AllGps$groupesRep==4),])
```

<p style="text-align:justify;">Encore une fois, on retrouve un groupe représentant assez bien la moyenne française. Il s'agit globalement des mêmes qu'en 1995. On notera cependant la disparition des Bouches du Rhône et de la Gironde qui ont une population rajeunissante.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
repartition <- PREDICTRICE[which(PREDICTRICE$Annee == 2015),2:13]
row.names(repartition) <- repartition$Lieu
repartition <- repartition[,-1]

#Génération des pourcentages : 

repartition <- repartition/repartition$Population_Francaise_Totale

repartition <- repartition[,-6]
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
dRepartition <- dist(repartition)
CAHRepartition <- hclust(dRepartition)
inertie <- sort(CAHRepartition$height, decreasing = TRUE)
plot(inertie[1:93], type = "s", xlab = "Nombre de classes", ylab = "Inertie Résiduelle")
title("Inertie résiduelle en fonction du nombre de classes")
points(c(5,8), inertie[c(5,8)], col = c("red3", "green3"), cex = 2, lwd = 3)
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
plot(CAHRepartition, main = "CAH de la répartition de la population des départements en 2015"  )
rect.hclust(CAHRepartition, k = 5, border = "red3")
rect.hclust(CAHRepartition, k = 8, border = "green3")
```

```{r, echo = FALSE, fig.height=12, fig.width=18}
groupesRep <- cutree(CAHRepartition, k = 8)
ALL <- repartition
AllGps <- as.data.frame(cbind(groupesRep, ALL))
MoyenneRep <- colMeans(AllGps)
for( i in 1:max(groupesRep)){
  
  DFi <- AllGps[which(AllGps$groupesRep==i),]
  GroupeI <- aggregate(.~groupesRep, data = DFi, FUN = mean)
  MoyenneRep<- rbind(MoyenneRep, GroupeI)
  
}
#print(MoyenneRep)
```

<p style="text-align:justify;">Pour finir, nous observons les répartitions en 2015. La modification la plus flagrante semble être la Seine Saint Denis qui possède désormais son propre groupe. Il s'agit, et de très loin, du département le plus jeune de France, avec plus de 28% d'enfants. Pour la majorité de la France, la population vieillit, à l'exception de Paris qui possède toujours une forte attractivité chez les jeunes actifs.</p>

<p style="text-align:justify;">On remarque également un groupe de départements très différent du reste de la France dans le sens où il est composé de plus de personnes de plus de 60 ans que de personnes de moins de 40 ans. Ce groupe est composé de départements très peu attractifs comme la Creuse, le Lot et le Cantal.</p>
```{r, echo = FALSE, fig.height=12, fig.width=18}
ii <- 5
rownames(AllGps[which(AllGps$groupesRep==ii),])
DFi <- AllGps[which(AllGps$groupesRep==ii),]
GroupeI <- t(aggregate(.~groupesRep, data = DFi, FUN = mean)[-1])
colnames(GroupeI) <- c(paste("groupe",ii))
GroupeI
```

\newpage
##Recherche variables explicatives, modèle linéaire simple



```{r variableS.explicatives, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
variables.explicatives <- list()
# evo.R2 <- list()
list_var <- colnames(PREDICTRICE2)
for(variable in list_var){
  # RR <- c()
  # VV <- c()
  
  "
  on veut sélectionner les variables le splus significative spour distinguer les individus entre eux.
  Les plus significatives au sens de la population totale
  "
  DATA <- cbind(PREDICTRICE2[variable],PREDICTEUR2)
  n <- names(PREDICTEUR2)
  f <- as.formula(paste(paste(variable,"~"),
                        paste(n[!n %in% "(Intercept)"], collapse = " + ")))
  model1.fit <- lm(f,data=DATA)
  sum_model1 <- summary(model1.fit)
  sum_model1 <- as.data.frame(sum_model1$coefficients)
  sum_model1 <- sum_model1[order(sum_model1$`Pr(>|t|)`),]
  
  n <- colnames(DATA)
  n <- n[!n %in% variable]
  sum_modelk <- sum_model1
  while((sum_modelk[nrow(sum_modelk),4] > 1e-50 && nrow(sum_modelk) >4) | (nrow(sum_modelk) >10)){
    pire <- Recup.pire.coef(sum_modelk)
    length(pire)
    n <- n[!n %in% pire]
    f <- as.formula(paste(paste(variable,"~"),
                          paste(n[!n %in% "(Intercept)"], collapse = " + ")))
    modelk <- lm(f,data=DATA)
    sum_modelk <- summary(modelk)
    # RR <- c(RR,modelk$adj.r.squared) # on récupère le R2
    sum_modelk <- as.data.frame(sum_modelk$coefficients)
    sum_modelk <- sum_modelk[order(sum_modelk$`Pr(>|t|)`),]
    sum_modelk <- sum_modelk[!rownames(sum_modelk) %in% "(Intercept)",]
    # VV <- c(VV,nrow(sum_modelk)) # on récupère le nombre de variables
  }
  n <- names(as.data.frame(t(sum_modelk)))
  variables.explicatives[variable] <- as.data.frame(n)
  # evodf <- as.data.frame(cbind(VV,RR))
  # colnames(evodf) <- c("NBvariable","R2")
  # evo.R2[variable][[1]] <- evodf
}
```

<p style="text-align:justify;">Le fichier contient environ 140 variables. Nous voulons évincer celles qui ne sont pas pertinentes et qui n'expliquent pas nos départements. Pour chaque population, nous enlevons le coefficient avec la p-value la plus grande. Nous itérons tant que la p-value est supérieure à E-50 ou bien que nous avons plus de 10 coefficients, tout en conservant au minimum 4 de ceux-ci. Avec les formules appropriées, nous arrivons à conserver les variables suivantes pour chaque catégorie de population:</p>

```{r affichage_variables_explicatives, echo=FALSE}
pops <- names(variables.explicatives)

pops[1]
as.character(variables.explicatives[[1]])
pops[2]
as.character(variables.explicatives[[2]])
pops[3]
as.character(variables.explicatives[[3]])
pops[4]
as.character(variables.explicatives[[4]])
pops[5]
as.character(variables.explicatives[[5]])
pops[6]
as.character(variables.explicatives[[6]])
pops[7]
as.character(variables.explicatives[[7]])
pops[8]
as.character(variables.explicatives[[8]])
pops[9]
as.character(variables.explicatives[[9]])
pops[10]
as.character(variables.explicatives[[10]])
pops[11]
as.character(variables.explicatives[[11]])
```

```{r bootstrap, echo=FALSE}
R2_hat <- NULL
REPET <- 1500
for(tranche_age in 1:length(variables.explicatives)){
  
  population <- names(variables.explicatives)[tranche_age]
  var_pop <- as.character(variables.explicatives[[population]])
  DATA <- cbind(PREDICTRICE2[,population],PREDICTEUR2[,var_pop])
  colnames(DATA)[1] <- population
  
  R2_MC <- NULL
  f <- as.formula(paste(paste(population," ~ "),paste(var_pop,collapse = " + ")))
  for(ii in 1:REPET){
    ####### FOR ###
    train_index <- sample(1:nrow(DATA), round(0.8*nrow(DATA)))
    train <- as.data.frame(DATA[train_index,])
    test <- as.data.frame(DATA[-train_index,])
    
    modelk <- lm(f,data=train)
    prevision <- predict(modelk,test)
    #ts.plot(test$Population_Francaise_Totale,col="tomato")
    #lines(prevision,col="forestgreen")
    
    new_R2 <- 1-sum((predict(modelk,test)-test[[population]])**2)/sum((mean(test[[population]])-test[[population]])**2)
    R2_MC <- c(R2_MC,new_R2)
  }
  R2_hat <- c(R2_hat,mean(R2_MC))

}
R2_hat <- data.frame(cbind(names(variables.explicatives),R2_hat))
colnames(R2_hat) <- c("Tranche de population","R2 ajusté")
```

<p style="text-align:justify;">Par bootstrap ont ré-échantillonne notre population en train / test à hauteur de 80% / 20% pour les échantillons d'entraînement et de test respectivement. Puis on calcule le R² sur la population cible. Nous itérons 1500 fois ici pour estimer les R² propres à chaque tranche de population. Nous obtenons les résultats suivants :</p>

```{r affiche_bootstraped, echo=FALSE}
R2_hat
```

<p style="text-align:justify;">Grâce à cette méthode, nous avons la certitude que nos variables explicatives sont très significatives. Tous les R² obtenus sur chaque tranche de population par bootstrap sur des échantillons de test sont largement au-dessus de 95% de significativité (98,6% pour le meilleur et 95% pour le pire). En étudiant les variables, nous avons remarqué que nous pouvions garder une trentaine de variables significatives. Mais toujours par principe de parcimonie, nous avons continué de les enlever une à une.</p>

<p style="text-align:justify;">Pour la suite, chaque département a été associé à un point. Nous étudions la répartition des populations des années 1995, 2005 et 2015 pour voir l'évolution des populations.</p>


\newpage
##Exploration des données



<p style="text-align:justify;">Pour la suite de l'étude, nous explorons les variables ainsi que les individus via des Analyses en Composantes Principales. Ci-dessous un tableau récapitulant le numéro attribué à chaque département pour la suite.</p>
```{r correspondance, echo=FALSE, fig.height=12, fig.width=18}
correspondance <- data.frame(unique(PREDICTEUR["Lieu"]))
colnames(correspondance) <- c("Département")
rownames(correspondance) <- 1:nrow(correspondance)
correspondance
```

```{r ACPs1,echo = FALSE, fig.height=12, fig.width=18}
population <- "Population_Francaise_Totale"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP1[population],PREDICTEUR.ACP1[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp1 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))


population <- "Population_Francaise_Totale"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP2[population],PREDICTEUR.ACP2[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp2 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))

population <- "Population_Francaise_Totale"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP3[population],PREDICTEUR.ACP3[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp3 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))
```

```{r ttACP1, echo=FALSE, fig.height=10, fig.width=9}
par(mfrow=c(3,2))
plot.PCA(acp1,title = "Répartition de la population française totale en 1995",choix = "ind")
plot.PCA(acp1,title = "Répartition de la population française totale en 1995",choix = "var")
plot.PCA(acp2,title = "Répartition de la population française totale en 2005",choix = "ind")
plot.PCA(acp2,title = "Répartition de la population française totale en 2005",choix = "var")
plot.PCA(acp3,title = "Répartition de la population française totale en 2015",choix = "ind")
plot.PCA(acp3,title = "Répartition de la population française totale en 2015",choix = "var")
```

<p style="text-align:justify;">Sur la population totale on peut remarquer trois groupes de départements qui ont tendance à se 'détacher' du reste: ce sont les départements correspondants aux villes de : Paris (70), Dunkerque (67) / Marseille (13), Le Havre (80) (qui sont les zones de population les plus denses dans ces départements). L'axe principal correspond à la population totale qui va de pair avec le nombre d'ordures ménagères collectées et le nombre d'établissements de soin. L'axe 2 comporte des nuances avec les départements maritimes plutôt en haut du cercle de corrélation et ceux en bas avec un grand nombre d'établissements entreposant les déchets. L'axe 1 correspond à l'activité d'un département: les départements situés à droite auront une forte activité commerciale / industrielle. L'axe 2 lui correspond plutôt à la densité du département. Le tissu urbain discontinu est une zone construite périphérique qui peut chevaucher des zones rurales. Paris a très peu de tissu urbain discontinu car c'est un département urbanisé à 100%. Un département avec une forte densité aura tendance à avoir plus de centres de transport et d'entreposage, il sera situé en bas à droite. Un département plus large, moins dense en moyenne aura de plus grande zones peu construites. Paris et Le Havre sont opposés selon l'axe 2: La Seine Maritime et L'Ile de France s'opposent car L'Ile de France est un département-ville composé de Paris uniquement (très forte densité) alors que Le Havre est un grand port avec une forte activité également mais plus rural (la ville n'est pas ce qui compose en majorité la Seine Maritime).</p>
```{r ACPs2,echo = FALSE, fig.height=12, fig.width=18}
population <- "Population_Feminine_0_19"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP1[population],PREDICTEUR.ACP1[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp1 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))


population <- "Population_Feminine_0_19"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP2[population],PREDICTEUR.ACP2[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp2 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))

population <- "Population_Feminine_0_19"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP3[population],PREDICTEUR.ACP3[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp3 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))
```

```{r ttACP2, echo=FALSE, fig.height=10, fig.width=10}
par(mfrow=c(3,2))
plot.PCA(acp1,title = "Répartition de la population féminine de 0 à 19 ans en 1995",choix = "ind")
plot.PCA(acp1,title = "Répartition de la population féminine de 0 à 19 ans en 1995",choix = "var")
plot.PCA(acp2,title = "Répartition de la population féminine de 0 à 19 ans en 2005",choix = "ind")
plot.PCA(acp2,title = "Répartition de la population féminine de 0 à 19 ans en 2005",choix = "var")
plot.PCA(acp3,title = "Répartition de la population féminine de 0 à 19 ans en 2015",choix = "ind")
plot.PCA(acp3,title = "Répartition de la population féminine de 0 à 19 ans en 2015",choix = "var")
```

<p style="text-align:justify;">Nous pouvons observer la même tendance avec la population féminine en bas âge : les départements avec des villes importantes ont tendance à se détacher. On remarque que en 1995, Paris ressemblait aux autres départements et que cette ville s'éloigne de plus en plus pour bien s'expliquer avec le revenu des ménages. L'axe 1 correspond également à l'activité et l'axe 2 à la densité du département (axes inversés pour les deux premières ACP sur la population féminine âgée de 0 à 19 ans). Mêmes conclusions qu'avec la population totale.</p>

```{r ACPs3,echo = FALSE, fig.height=12, fig.width=18}
population <- "Population_Masculine_40_59"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP1[population],PREDICTEUR.ACP1[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp1 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))


population <- "Population_Masculine_40_59"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP2[population],PREDICTEUR.ACP2[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp2 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))

population <- "Population_Masculine_40_59"
var_pop <- as.character(variables.explicatives[[population]])
#DATA <- cbind(PREDICTRICE2,PREDICTEUR2[var_pop])
DATA <- cbind(PREDICTRICE.ACP3[population],PREDICTEUR.ACP3[var_pop])
rownames(DATA) <- 1:nrow(DATA)

DATA.acp.scaled <- scale(DATA)
acp3 <- PCA(DATA.acp.scaled , graph = FALSE, quanti.sup = c(1))
```

```{r ttACP3, echo=FALSE, fig.height=10, fig.width=10}
par(mfrow=c(3,2))
plot.PCA(acp1,title = "Répartition de la population masculine de 40 à 59 ans en 1995",choix = "ind")
plot.PCA(acp1,title = "Répartition de la population masculine de 40 à 59 ans en 1995",choix = "var")
plot.PCA(acp2,title = "Répartition de la population masculine de 40 à 59 ans en 2005",choix = "ind")
plot.PCA(acp2,title = "Répartition de la population masculine de 40 à 59 ans en 2005",choix = "var")
plot.PCA(acp3,title = "Répartition de la population masculine de 40 à 59 ans en 2015",choix = "ind")
plot.PCA(acp3,title = "Répartition de la population masculine de 40 à 59 ans en 2015",choix = "var")
```

<p style="text-align:justify;">Concernant les hommes âgés de 40 à 59 ans, de mêmes que la population totale et la population féminine en bas âge, ils sont bien expliqués par l'axe 1 qui est lié à l'activité du département. L'axe 2 reste toujours lié à la densité du département. On remarque que Paris se détache nettement du au grand nombre de ses établissements. Les hommes dans la tranche d'âge entre 40 et 59 ans sont des travailleurs actifs et cadres la plupart du temps, donc bien expliqués par Paris.</p>



<p style="text-align:justify;">Pour chacune des analyses factorielles réalisées, les axes construits représentent l'activité ainsi que la densité d'un département. On peut remarquer que les départements actifs côtiers s'opposent aux départements actifs qui ont un grand nombre d'établissements d'activité. Nous arrivons à estimer de manière très efficace le nombre de personnes dans un département, mais il faut transformer ces chiffres pour obtenir des répartitions de population. Le problème est que justement la population en nombre s'explique bien car elle est très corrélée à d'autres variables (plus il y a de personnes, plus la production d'ordures ménagères sera important, etc .). Nous allons désormais nous intéresser à la population par tranche d'âge en pourcentage pour estimer les proportions directement en supprimant les biais indiqués plus haut (les corrélations ordures ménagères / population par exemple) et voir si nos estimations sont toujours aussi performantes ou non. Pour ce faire nous allons construire des modèles logistiques établis sur des proportions pour estimer directement les proportions de la population et remarquer les nouveaux facteurs explicatifs potentiels.</p>

```{r importation_3, echo=FALSE, fig.height=12, fig.width=18}
PREDICTRICE3 <- PREDICTRICE2[,c("Population_Feminine_0_19",
                                "Population_Feminine_19_39",
                                "Population_Feminine_40_59",
                                "Population_Feminine_60_74",
                                "Population_Feminine_75",
                                "Population_Masculine_0_19",
                                "Population_Masculine_19_39",
                                "Population_Masculine_40_59",
                                "Population_Masculine_60_74",
                                "Population_Masculine_75")]/PREDICTRICE2[,"Population_Francaise_Totale"]
```


\newpage
##Recherche des variables explicatives, modèle logistique



<p style="text-align:justify;">Nous recherchons pour chaque tranche de population les variables les plus significatives. Pour ce faire, nous itérons les régressions linéaires en enlevant à chaque tour de boucle la variable avec la p-value la plus élevée. Nous nous arrêtons à au moins 4 variables et au plus 10 variables avec une p-value inférieure à E-50.</p>

```{r variableS.explicatives_log, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=12, fig.width=18}
variables.explicatives_log <- list()
# evo.R2 <- list()
list_var <- colnames(PREDICTRICE2)
list_var <- list_var[!list_var %in% c("Population_Francaise_Totale")]
for(variable in list_var){
  # RR <- c()
  # VV <- c()
  
  DATA_log <- cbind(PREDICTRICE2[variable],PREDICTRICE2[c("Population_Francaise_Totale")],PREDICTEUR2)
  
  "
  on veut sélectionner les variables le splus significative spour distinguer les individus entre eux.
  Les plus significatives au sens de la population totale
  "
  
  n <- names(PREDICTEUR2)
  
  f <- as.formula(paste(paste("as.matrix(cbind(",variable,",Population_Francaise_Totale-",variable,")) ~",sep=""),paste("",paste(n[!n %in% "(Intercept)"], collapse = " + "),sep = "")))
  
  model1.fit <- glm(f,data=DATA_log,family=binomial(link=logit))
  sum_model1 <- summary(model1.fit)
  sum_model1 <- as.data.frame(sum_model1$coefficients)
  sum_model1 <- sum_model1[order(sum_model1$`Pr(>|z|)`),]
  
  sum_modelk <- sum_model1
  
  while((sum_modelk[nrow(sum_modelk),4] > 1e-50 && nrow(sum_modelk) >4) | (nrow(sum_modelk) >10)){
    pire <- Recup.pire.coef_log(sum_modelk)
    n <- n[!n %in% pire]
    f <- as.formula(paste(paste("as.matrix(cbind(",variable,",Population_Francaise_Totale-",variable,")) ~",sep=""),paste("",paste(n[!n %in% "(Intercept)"], collapse = " + "),sep = "")))
    
    modelk <- glm(f,data=DATA_log,family=binomial(link=logit))
    sum_modelk <- summary(modelk)
    #attributes(sum_modelk)
    #sum_modelk$null.deviance
    
    #RR <- c(RR,sum_modelk$) # on récupère le R2
    sum_modelk <- as.data.frame(sum_modelk$coefficients)
    sum_modelk <- sum_modelk[order(sum_modelk$`Pr(>|z|)`),]
    sum_modelk <- sum_modelk[!rownames(sum_modelk) %in% "(Intercept)",]
    # VV <- c(VV,nrow(sum_modelk)) # on récupère le nombre de variables
  }
  n <- names(as.data.frame(t(sum_modelk)))
  variables.explicatives_log[variable] <- as.data.frame(n)
  # evodf <- as.data.frame(cbind(VV,RR))
  # colnames(evodf) <- c("NBvariable","R2")
  # evo.R2[variable][[1]] <- evodf
}
```

```{r affichage_variables_explicatives_log, echo=FALSE}
pops <- names(variables.explicatives_log)

pops[1]
as.character(variables.explicatives_log[[1]])
pops[2]
as.character(variables.explicatives_log[[2]])
pops[3]
as.character(variables.explicatives_log[[3]])
pops[4]
as.character(variables.explicatives_log[[4]])
pops[5]
as.character(variables.explicatives_log[[5]])
pops[6]
as.character(variables.explicatives_log[[6]])
pops[7]
as.character(variables.explicatives_log[[7]])
pops[8]
as.character(variables.explicatives_log[[8]])
pops[9]
as.character(variables.explicatives_log[[9]])
pops[10]
as.character(variables.explicatives_log[[10]])
```

```{r bootstrap_log, echo=FALSE, fig.height=12, fig.width=18}
R2_hat_log <- NULL
REPET <- 500
for(tranche_age in 1:length(variables.explicatives_log)){
  # tranche_age <- 4
  population <- names(variables.explicatives_log)[tranche_age]
  var_pop <- as.character(variables.explicatives_log[[population]])
  DATA <- cbind(PREDICTRICE2[population],PREDICTRICE2["Population_Francaise_Totale"],PREDICTEUR2[,var_pop])
  
  R2_MC <- NULL
  f <- as.formula(paste(paste("as.matrix(cbind(",population,",Population_Francaise_Totale-",population,")) ~",sep=""),paste("",paste(var_pop[!var_pop %in% "(Intercept)"], collapse = " + "),sep = "")))
  for(ii in 1:REPET){
    ####### FOR ###
    train_index <- sample(1:nrow(DATA), round(0.8*nrow(DATA)))
    train <- as.data.frame((DATA[train_index,]))
    x_test <- as.matrix(PREDICTEUR2[-train_index,var_pop])
    y_test <- c(PREDICTRICE3[-train_index,population])
    colnames(test)[1] <- "Intercept"
    
    modelk <- glm(f,data=train,family=binomial(link=logit))
    # summary(modelk)
    
    # y_test <- PREDICTRICE3[[population]][train_index]
    
    prevision <- predict(modelk,as.data.frame(x_test),type="response")
    
    # ts.plot(y_test,col="forestgreen",ylim=c(0,1))
    # lines(prevision,col="tomato")
    
    new_R2 <- 1-sum((prevision-y_test)**2)/sum((mean(y_test)-y_test)**2)
    
    R2_MC <- c(R2_MC,new_R2)
  }
  R2_hat_log <- c(R2_hat_log,mean(R2_MC))

}
R2_hat_log <- data.frame(cbind(names(variables.explicatives_log),R2_hat_log))
colnames(R2_hat_log) <- c("Tranche de population","R2 ajusté")
```

```{r affiche_bootstraped_log, echo=FALSE, fig.height=12, fig.width=18}
R2_hat_log
```

<p style="text-align:justify;">En regardant les R² ajustés, on se rend compte que les modèles de régressions logistiques sur proportions ne sont pas adaptés au problème, les R² sont en effet révélateurs d'un modèle très perfectible. Ajuster nos prévisions sur ces modèles donnent une prévision qui est pire que la moyenne. Voici un exemple de prévision d'un modèle logistique sur proportions:</p>

```{r exemple_log, echo= FALSE, fig.height=12, fig.width=18}
population <- "Population_Masculine_40_59"
var_pop <- as.character(variables.explicatives_log[[population]])
DATA_log <- cbind(PREDICTRICE2[population],PREDICTRICE2["Population_Francaise_Totale"],PREDICTEUR2[,var_pop])
  
f <- as.formula(paste(paste("as.matrix(cbind(",population,",Population_Francaise_Totale-",population,")) ~",sep=""),paste("",paste(var_pop[!var_pop %in% "(Intercept)"], collapse = " + "),sep = "")))

train_index <- sample(1:nrow(DATA), round(0.8*nrow(DATA)))
train <- as.data.frame((DATA[train_index,]))
x_test <- as.matrix(cbind(1,as.data.frame((PREDICTEUR2[-train_index,var_pop]))))
y_test <- c(PREDICTRICE3[-train_index,population])
colnames(test)[1] <- "Intercept"

modelk <- glm(f,data=DATA_log,family=binomial(link=logit))
# summary(modelk)

BB <- t(t(modelk$coefficients))
# y_test <- PREDICTRICE3[[population]][train_index]

prevision <- c(logistique(x_test,BB))

ts.plot(y_test,col="forestgreen",ylim=c(0.1,0.2),xlab="index",ylab="proportion",type="p")
lines(prevision,col="tomato",type="p")
legend("topleft",c("réel","prévision"),pch=c(1,1),col=c("forestgreen","tomato"))
title("proportion de la population masculine agée de 60 à 74 ans")

```

<p style="text-align:justify;">Nous voyons bien que les prévisions sont très proches des proportions réelles. Nous conservons néanmoins le modèle pour pouvoir le tester dans la partie finale de l'étude. Gardons quand même à l'esprit la faible significativité des modèles logistiques.</p>



\newpage
##Test du modèle de regression linéaire multiple :

<p style="text-align:justify;">Nous allons commencer par séparer le jeu de données en un jeu de test et un jeu d'entrainement. Nous allons utiliser les années 2013 à 2015 en test. L'idée serait de calculer un modèle pour chaque année à partir de toutes les informations antérieures dont on dispose. Après avoir séparé le jeu de données, nous allons entraîner un modèle sur le jeu d'entraînement et estimer nos années de test. Ensuite, nous calculerons les proportions.</p>

```{r creer Data-Frame, echo=FALSE, fig.height=12, fig.width=18}
DFtrain <- list()
DFtest <- list()
annees <- list(2013,2014,2015)
variablesReponse <- names(PREDICTRICE)[3:length(names(PREDICTRICE))]
for(variableReponse in variablesReponse){
  variablesExpl <- as.character(variables.explicatives[[variableReponse]])
  for(annee in annees){
    nom <- paste(variableReponse, as.character(annee), sep="_")
    DFtrain[[nom]]<- cbind(PREDICTEUR[-which(PREDICTEUR$Annee %in% annees),variablesExpl],PREDICTRICE[-which(PREDICTEUR$Annee %in% annees),variableReponse])
    names(DFtrain[[nom]])[length(names(DFtrain[[nom]]))] <- variableReponse
    DFtest[[nom]]<- cbind(PREDICTEUR[which(PREDICTEUR$Annee == annee),variablesExpl],PREDICTRICE[which(PREDICTEUR$Annee == annee),variableReponse])
    names(DFtest[[nom]])[length(names(DFtest[[nom]]))] <- variableReponse
  }
}
```

```{r, echo=FALSE, fig.height=12, fig.width=18}
modelt <- list()
DF_repartition <- list()

variableReponse <- variablesReponse[1]
for (annee in annees) {
  nom <- paste(variableReponse, as.character(annee), sep="_")
  DF_repartition[[as.character(annee)]]<- DFtest[[nom]][variableReponse]  
}

for(variableReponse in variablesReponse){
  f <- as.formula(paste(variableReponse, ".", sep = " ~ "))
  for(annee in annees){
    nom <- paste(variableReponse, as.character(annee), sep="_")
    modelt[[paste(variableReponse, as.character(annee), sep = "_")]] <- lm(formula = f, data = DFtrain[[nom]])
    prediction <- predict(modelt[[paste(variableReponse, as.character(annee), sep = "_")]], DFtest[[nom]])
    DFtest[[nom]] <- cbind(DFtest[[nom]],prediction)
    DF_repartition[[as.character(annee)]]<-cbind(cbind(DF_repartition[[as.character(annee)]],DFtest[[nom]][variableReponse]),as.data.frame(prediction))
    nem <- paste("prediction", variableReponse, sep = "_")
    colnames(DF_repartition[[as.character(annee)]]) <- c(colnames(DF_repartition[[as.character(annee)]])[1:(ncol(DF_repartition[[as.character(annee)]])-1)],nem)
    }
}

for (annee in annees) {
  DF_repartition[[as.character(annee)]]<-DF_repartition[[as.character(annee)]][,2:ncol(DF_repartition[[as.character(annee)]])] 
  DF_repartition[[as.character(annee)]][c("previsionTotale")] <- rowSums(DF_repartition[[as.character(annee)]][c(2,4,6,8,10,14,16,18,20,22)])
} 
# summary(modelt[[paste(variableReponse, as.character(annee), sep = "_")]])
# predict(modelt[[paste(variableReponse, as.character(annee), sep = "_")]], DFtest[[nom]])

plot(DFtest[["Population_Feminine_0_19_2015"]]$Population_Feminine_0_19, xlab = "département", ylab = "effectifs", col = "forestgreen")
points(DFtest[["Population_Feminine_0_19_2015"]]$prediction, col = "red")
title( "Population féminine de 0 à 19 ans")
legend("topleft", pch = 1, col = c("forestgreen", "red"), c("réel", "prévu"))


```

###Calcul du R² total:

<p style="text-align:justify;">Comme on a plusieurs variables à expliquer, on fait la somme sur non plus une variable mais la totalité de nos effectifs estimées. On obtient donc le R² du modèle complet. Le R² calculé sur l'année 2015 grâce à la régression linéaire multiple est de 0,953. On a donc un modèle assez efficace permettant, à partir des caractéristiques d'occupation du territoire, d'obtenir les effectifs de la population française par tranche d'âge très proches de la réalité.</p>

```{r, echo=FALSE, fig.height=12, fig.width=18}
moyenne <- list()
R2 <- list()  

moyenne[[as.character(annee)]] <- colMeans(DF_repartition[[as.character(annee)]])
  
  SCR2 <- NULL
  SCR <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCR2<- c(SCR2,(sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)))
    SCR <- SCR + sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)
    
  }
  
  SCT2 <- NULL
  SCT <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCT2<- c(SCT2,sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2))
    SCT <- SCT + sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2)
    
  }


  R2[[as.character(annee)]] <- 1-SCR/SCT
  print(R2[[as.character(annee)]])



```

###Calcul des proportions :

<p style="text-align:justify;">L'objectif final était toutefois de calculer les proportions de chaque tranche d'âge et non pas la quantité d'individus par tranche d'âge. On calcule donc pour chaque tranche la proportion d'individus par rapport à la population totale du département. Cette population est la somme de tous les effectifs estimés.</p>


```{r, echo = FALSE, fig.height=12, fig.width=18}

for (annee in annees) {
  #Prévisions
  DF_repartition[[as.character(annee)]][c(2,4,6,8,10,14,16,18,20,22)] <- DF_repartition[[as.character(annee)]][c(2,4,6,8,10,14,16,18,20,22)]/DF_repartition[[as.character(annee)]]$previsionTotale
  #Réel
    DF_repartition[[as.character(annee)]][c(1,3,5,7,9,13,15,17,19,21)] <- DF_repartition[[as.character(annee)]][c(1,3,5,7,9,13,15,17,19,21)]/DF_repartition[[as.character(annee)]]$Population_Francaise_Totale
    DF_repartition[[as.character(annee)]]$previsionTotale<-1
    DF_repartition[[as.character(annee)]]$Population_Francaise_Totale<-1
}

DF_TMP <- DF_repartition[["2015"]]
head(DF_TMP[!(DF_TMP %in% c("Population_Francaise_Totale","prediction_Population_Francaise_Totale"))])
```


###Calcul du R² pour les proportions

<p style="text-align:justify;">On calcule donc le R² pour les proportions calculées précédemment. On obtient ainsi un R² négatif, nous signifiant un modèle pire que la moyenne des proportions sur le territoire. Le modèle de régression linéaire multiple n'est donc pas efficace pour notre problème.</p>


```{r, echo = FALSE, fig.height=12, fig.width=18}
moyenne <- list()
R2 <- list()
for (annee in annees) {
  moyenne[[as.character(annee)]] <- colMeans(DF_repartition[[as.character(annee)]])
  
  SCR2 <- NULL
  SCR <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCR2<- c(SCR2,(sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)))
    SCR <- SCR + sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)
    
  }
  
  SCT2 <- NULL
  SCT <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCT2<- c(SCT2,sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2))
    SCT <- SCT + sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2)
    
  }


  R2[[as.character(annee)]] <- 1-SCR/SCT
} 
print(R2[[as.character(annee)]])
```




\newpage
##Test du modèle de regression logistique :

<p style="text-align:justify;">Nous allons exécuter la même procédure que pour les modèles de régression linéaire multiple afin de tester l'efficacité des modèle logistique sur nos données.</p>
```{r creer Data-Frame 2, echo=FALSE, fig.height=12, fig.width=18}
DFtrainLog <- list()
DFtestLog <- list()
popTotaleTrainLog <- list()
popTotaleTestLog <- list()
annees <- list(2013,2014,2015)
variablesReponseLog <- names(PREDICTRICE)[3:length(names(PREDICTRICE))]
nomPopTotaleLog <- variablesReponseLog[6]
variablesReponseLog <- variablesReponseLog[-6]
for(variableReponseLog in variablesReponseLog){
  variablesExpl <- as.character(variables.explicatives_log[[variableReponseLog]])
  minusAnnees<- as.vector(annees)
  for(annee in annees){
    nom <- paste(variableReponseLog, as.character(annee), sep="_")
    DFtrainLog[[nom]]<- cbind(PREDICTEUR[-which(PREDICTEUR$Annee %in% minusAnnees),variablesExpl],PREDICTRICE[-which(PREDICTEUR$Annee %in% minusAnnees),variableReponseLog])
    names(DFtrainLog[[nom]])[length(names(DFtrainLog[[nom]]))] <- variableReponseLog
    DFtestLog[[nom]]<- cbind(PREDICTEUR[which(PREDICTEUR$Annee == annee),variablesExpl],PREDICTRICE[which(PREDICTEUR$Annee == annee),variableReponseLog])
    names(DFtestLog[[nom]])[length(names(DFtestLog[[nom]]))] <- variableReponseLog
    minusAnnees <- minusAnnees[-c(1)]
  }
}
minusAnnees<- annees
for(annee in annees){
    popTotaleTrainLog[[as.character(annee)]] <- PREDICTRICE[-which(PREDICTRICE$Annee %in% minusAnnees),nomPopTotaleLog]
    popTotaleTestLog[[as.character(annee)]] <- PREDICTRICE[which(PREDICTRICE$Annee == annee),nomPopTotaleLog]
    minusAnnees <- minusAnnees[-c(1)]
 }
```


```{r, echo=FALSE, fig.height=12, fig.width=18}
modell <- list()
DF_repartition_Log <- list()

variableReponseLog <- variablesReponseLog[1]
for (annee in annees) {
  nom <- paste(variableReponseLog, as.character(annee), sep="_")
  DF_repartition_Log[[as.character(annee)]]<- DFtestLog[[nom]][variableReponseLog]
}

for(variableReponseLog in variablesReponseLog){
  
  
  
  for(annee in annees){
    nom <- paste(variableReponseLog, as.character(annee), sep="_")
    f <- as.formula(paste(paste("as.matrix(cbind(",DFtrainLog[[nom]][variableReponseLog],",popTotaleTrainLog[[as.character(annee)]]-",DFtrainLog[[nom]][variableReponseLog],")) ~",sep=""),".",sep = ""))
    modell[[nom]] <- glm(formula = f, data = DFtrainLog[[nom]], family=binomial(link = logit))
    prediction <- predict(modell[[nom]], DFtestLog[[nom]], type = "response")
    DFtestLog[[nom]] <- cbind(DFtestLog[[nom]],prediction)
    DF_repartition_Log[[as.character(annee)]]<-cbind(cbind(DF_repartition_Log[[as.character(annee)]],DFtestLog[[nom]][variableReponseLog]),as.data.frame(prediction))
    nem <- paste("prediction", variableReponseLog, sep = "_")
    colnames(DF_repartition_Log[[as.character(annee)]]) <- c(colnames(DF_repartition_Log[[as.character(annee)]])[1:(ncol(DF_repartition_Log[[as.character(annee)]])-1)],nem)
    }
}

for (annee in annees) {
  DF_repartition_Log[[as.character(annee)]]<-DF_repartition_Log[[as.character(annee)]][,2:ncol(DF_repartition_Log[[as.character(annee)]])] 
  DF_repartition_Log[[as.character(annee)]][c("popTotaleLog")] <- popTotaleTestLog[[as.character(annee)]]
  DF_repartition_Log[[as.character(annee)]][c("previsionTotale")] <- rowSums(DF_repartition_Log[[as.character(annee)]][c(2,4,6,8,10,12,14,16,18,20)])
  
} 
# summary(modell[[paste(variableReponseLog, as.character(annee), sep = "_")]])
# predict(modell[[paste(variableReponseLog, as.character(annee), sep = "_")]], DFtestLog[[nom]])

```

```{r, echo = FALSE, fig.height=12, fig.width=18}

for (annee in annees) {
  #Prévisions
  DF_repartition_Log[[as.character(annee)]][c(2,4,6,8,10,12,14,16,18,20)] <- DF_repartition_Log[[as.character(annee)]][c(2,4,6,8,10,12,14,16,18,20)]/DF_repartition_Log[[as.character(annee)]]$previsionTotale
  #Réel
    DF_repartition_Log[[as.character(annee)]][c(1,3,5,7,9,11,13,15,17,19)] <- DF_repartition_Log[[as.character(annee)]][c(1,3,5,7,9,11,13,15,17,19)]/DF_repartition_Log[[as.character(annee)]]$popTotaleLog
    DF_repartition_Log[[as.character(annee)]]$previsionTotale<-1
    DF_repartition_Log[[as.character(annee)]]$popTotaleLog<-1
}

plot(DF_repartition_Log[["2013"]]$Population_Feminine_0_19, xlab = "département", ylab = "effectifs", col = "forestgreen")
points(DF_repartition_Log[["2013"]]$prediction_Population_Feminine_0_19, col = "red")
title( "Population féminine de 0 à 19 ans")
legend("topleft", pch = 1, col = c("forestgreen", "red"), c("réel", "prévu"))
```


###Calcul des proportions :

<p style="text-align:justify;">Même si l'on estime directement les proportions dans ce modèle, il est nécessaire de normaliser les proportions pour qu'elles soient égales à 1.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
head(DF_repartition_Log[["2015"]])
```

###Calcul du R² total:

<p style="text-align:justify;">Encore une fois, le R² n'est pas impressionnant. On obtient ici un R² de 0,03. Cependant, on gagne en efficacité par rapport à la régression linéaire multiple et le modèle reste meilleur que la moyenne.</p>


```{r, echo = FALSE, fig.height=12, fig.width=18}
moyenneLog <- list()
R2Log <- list()
for (annee in annees) {
  moyenneLog[[as.character(annee)]] <- colMeans(DF_repartition_Log[[as.character(annee)]])
  
  SCR <- 0
  for(groupe in c(1,3,5,7,9,11,13,15,17,19)){
    
    SCR <- SCR + sum((DF_repartition_Log[[as.character(annee)]][groupe]-DF_repartition_Log[[as.character(annee)]][groupe+1])**2)
    
  }

  SCT <- 0
  for(groupe in c(1,3,5,7,9,11,13,15,17,19)){
    
    SCT <- SCT + sum((DF_repartition_Log[[as.character(annee)]][groupe]-moyenneLog[[as.character(annee)]][groupe])**2)
    
  }

  R2Log[[as.character(annee)]] <- 1-SCR/SCT
} 

print(R2Log[[as.character(2015)]])

```


\newpage
#Test du modèle linéaire avec 20 variables

```{r variableS.explicatives2, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
variables.explicatives <- list()
# evo.R2 <- list()
list_var <- colnames(PREDICTRICE2)
for(variable in list_var){
  # RR <- c()
  # VV <- c()
  
  "
  on veut sélectionner les variables le splus significative spour distinguer les individus entre eux.
  Les plus significatives au sens de la population totale
  "
  DATA <- cbind(PREDICTRICE2[variable],PREDICTEUR2)
  n <- names(PREDICTEUR2)
  f <- as.formula(paste(paste(variable,"~"),
                        paste(n[!n %in% "(Intercept)"], collapse = " + ")))
  model1.fit <- lm(f,data=DATA)
  sum_model1 <- summary(model1.fit)
  sum_model1 <- as.data.frame(sum_model1$coefficients)
  sum_model1 <- sum_model1[order(sum_model1$`Pr(>|t|)`),]
  
  n <- colnames(DATA)
  n <- n[!n %in% variable]
  sum_modelk <- sum_model1
  while((sum_modelk[nrow(sum_modelk),4] > 0.05 && nrow(sum_modelk) >4) | (nrow(sum_modelk) >20)){
    pire <- Recup.pire.coef(sum_modelk)
    length(pire)
    n <- n[!n %in% pire]
    f <- as.formula(paste(paste(variable,"~"),
                          paste(n[!n %in% "(Intercept)"], collapse = " + ")))
    modelk <- lm(f,data=DATA)
    sum_modelk <- summary(modelk)
    # RR <- c(RR,modelk$adj.r.squared) # on récupère le R2
    sum_modelk <- as.data.frame(sum_modelk$coefficients)
    sum_modelk <- sum_modelk[order(sum_modelk$`Pr(>|t|)`),]
    sum_modelk <- sum_modelk[!rownames(sum_modelk) %in% "(Intercept)",]
    # VV <- c(VV,nrow(sum_modelk)) # on récupère le nombre de variables
  }
  n <- names(as.data.frame(t(sum_modelk)))
  variables.explicatives[variable] <- as.data.frame(n)
  # evodf <- as.data.frame(cbind(VV,RR))
  # colnames(evodf) <- c("NBvariable","R2")
  # evo.R2[variable][[1]] <- evodf
}
```

```{r bootstrap2, echo=FALSE}
R2_hat <- NULL
REPET <- 1500
for(tranche_age in 1:length(variables.explicatives)){
  
  population <- names(variables.explicatives)[tranche_age]
  var_pop <- as.character(variables.explicatives[[population]])
  DATA <- cbind(PREDICTRICE2[,population],PREDICTEUR2[,var_pop])
  colnames(DATA)[1] <- population
  
  R2_MC <- NULL
  f <- as.formula(paste(paste(population," ~ "),paste(var_pop,collapse = " + ")))
  for(ii in 1:REPET){
    ####### FOR ###
    train_index <- sample(1:nrow(DATA), round(0.8*nrow(DATA)))
    train <- as.data.frame(DATA[train_index,])
    test <- as.data.frame(DATA[-train_index,])
    
    modelk <- lm(f,data=train)
    prevision <- predict(modelk,test)
    #ts.plot(test$Population_Francaise_Totale,col="tomato")
    #lines(prevision,col="forestgreen")
    
    new_R2 <- 1-sum((predict(modelk,test)-test[[population]])**2)/sum((mean(test[[population]])-test[[population]])**2)
    R2_MC <- c(R2_MC,new_R2)
  }
  R2_hat <- c(R2_hat,mean(R2_MC))

}
R2_hat <- data.frame(cbind(names(variables.explicatives),R2_hat))
colnames(R2_hat) <- c("Tranche de population","R2 ajusté")
```

<p style="text-align:justify;">Le R² obtenu par bootstrap 80% / 20% sur le modèle linéaire.</p>
```{r affiche_bootstraped2, echo=FALSE}
R2_hat
```


```{r creer Data-Frame2, echo=FALSE, fig.height=12, fig.width=18}
DFtrain <- list()
DFtest <- list()
annees <- list(2013,2014,2015)
variablesReponse <- names(PREDICTRICE)[3:length(names(PREDICTRICE))]
for(variableReponse in variablesReponse){
  variablesExpl <- as.character(variables.explicatives[[variableReponse]])
  for(annee in annees){
    nom <- paste(variableReponse, as.character(annee), sep="_")
    DFtrain[[nom]]<- cbind(PREDICTEUR[-which(PREDICTEUR$Annee %in% annees),variablesExpl],PREDICTRICE[-which(PREDICTEUR$Annee %in% annees),variableReponse])
    names(DFtrain[[nom]])[length(names(DFtrain[[nom]]))] <- variableReponse
    DFtest[[nom]]<- cbind(PREDICTEUR[which(PREDICTEUR$Annee == annee),variablesExpl],PREDICTRICE[which(PREDICTEUR$Annee == annee),variableReponse])
    names(DFtest[[nom]])[length(names(DFtest[[nom]]))] <- variableReponse
  }
}
```

```{r, echo=FALSE, fig.height=12, fig.width=18}
modelt <- list()
DF_repartition <- list()

variableReponse <- variablesReponse[1]
for (annee in annees) {
  nom <- paste(variableReponse, as.character(annee), sep="_")
  DF_repartition[[as.character(annee)]]<- DFtest[[nom]][variableReponse]  
}

for(variableReponse in variablesReponse){
  f <- as.formula(paste(variableReponse, ".", sep = " ~ "))
  for(annee in annees){
    nom <- paste(variableReponse, as.character(annee), sep="_")
    modelt[[paste(variableReponse, as.character(annee), sep = "_")]] <- lm(formula = f, data = DFtrain[[nom]])
    prediction <- predict(modelt[[paste(variableReponse, as.character(annee), sep = "_")]], DFtest[[nom]])
    DFtest[[nom]] <- cbind(DFtest[[nom]],prediction)
    DF_repartition[[as.character(annee)]]<-cbind(cbind(DF_repartition[[as.character(annee)]],DFtest[[nom]][variableReponse]),as.data.frame(prediction))
    nem <- paste("prediction", variableReponse, sep = "_")
    colnames(DF_repartition[[as.character(annee)]]) <- c(colnames(DF_repartition[[as.character(annee)]])[1:(ncol(DF_repartition[[as.character(annee)]])-1)],nem)
    }
}

for (annee in annees) {
  DF_repartition[[as.character(annee)]]<-DF_repartition[[as.character(annee)]][,2:ncol(DF_repartition[[as.character(annee)]])] 
  DF_repartition[[as.character(annee)]][c("previsionTotale")] <- rowSums(DF_repartition[[as.character(annee)]][c(2,4,6,8,10,14,16,18,20,22)])
} 
# summary(modelt[[paste(variableReponse, as.character(annee), sep = "_")]])
# predict(modelt[[paste(variableReponse, as.character(annee), sep = "_")]], DFtest[[nom]])

plot(DFtest[["Population_Feminine_0_19_2015"]]$Population_Feminine_0_19, xlab = "département", ylab = "effectifs", col = "forestgreen")
points(DFtest[["Population_Feminine_0_19_2015"]]$prediction, col = "red")
title( "Population féminine de 0 à 19 ans")
legend("topleft", pch = 1, col = c("forestgreen", "red"), c("réel", "prévu"))


```

<p style="text-align:justify;">La prévision linéaire est réellement de qualité avec le modèle sur les effectifs</p>

###Calcul du R² total:

<p style="text-align:justify;">Le R² total du modèle linéaire est encore meilleur losque le nombre de variable augmente.</p>

```{r, echo=FALSE, fig.height=12, fig.width=18}
moyenne <- list()
R2 <- list()  

moyenne[[as.character(annee)]] <- colMeans(DF_repartition[[as.character(annee)]])
  
  SCR2 <- NULL
  SCR <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCR2<- c(SCR2,(sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)))
    SCR <- SCR + sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)
    
  }
  
  SCT2 <- NULL
  SCT <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCT2<- c(SCT2,sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2))
    SCT <- SCT + sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2)
    
  }


  R2[[as.character(annee)]] <- 1-SCR/SCT
  print(R2[[as.character(annee)]])



```

###Calcul des proportions :

<p style="text-align:justify;">Même les proportions semblent plutôt cohérentes, mis à part quelques écarts.</p>


```{r, echo = FALSE, fig.height=12, fig.width=18}

for (annee in annees) {
  #Prévisions
  DF_repartition[[as.character(annee)]][c(2,4,6,8,10,14,16,18,20,22)] <- DF_repartition[[as.character(annee)]][c(2,4,6,8,10,14,16,18,20,22)]/DF_repartition[[as.character(annee)]]$previsionTotale
  #Réel
    DF_repartition[[as.character(annee)]][c(1,3,5,7,9,13,15,17,19,21)] <- DF_repartition[[as.character(annee)]][c(1,3,5,7,9,13,15,17,19,21)]/DF_repartition[[as.character(annee)]]$Population_Francaise_Totale
    DF_repartition[[as.character(annee)]]$previsionTotale<-1
    DF_repartition[[as.character(annee)]]$Population_Francaise_Totale<-1
}

DF_TMP <- DF_repartition[["2015"]]
head(DF_TMP[!(DF_TMP %in% c("Population_Francaise_Totale","prediction_Population_Francaise_Totale"))])
```


###Calcul du R² pour les proportions

<p style="text-align:justify;">Mais le R² sur les proportions reste quand même bien pire que la moyenne.</p>


```{r, echo = FALSE, fig.height=12, fig.width=18}
moyenne <- list()
R2 <- list()
for (annee in annees) {
  moyenne[[as.character(annee)]] <- colMeans(DF_repartition[[as.character(annee)]])
  
  SCR2 <- NULL
  SCR <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCR2<- c(SCR2,(sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)))
    SCR <- SCR + sum((DF_repartition[[as.character(annee)]][,groupe]-DF_repartition[[as.character(annee)]][,groupe+1])**2)
    
  }
  
  SCT2 <- NULL
  SCT <- 0
  for(groupe in c(1,3,5,7,9,13,15,17,19,21)){
    SCT2<- c(SCT2,sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2))
    SCT <- SCT + sum((DF_repartition[[as.character(annee)]][,groupe]-moyenne[[as.character(annee)]][groupe])**2)
    
  }


  R2[[as.character(annee)]] <- 1-SCR/SCT
} 
print(R2[[as.character(annee)]])
```






\newpage
#Test du modèle logistique avec 20 variables

```{r variableS.explicatives_log2, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=12, fig.width=18}
variables.explicatives_log <- list()
# evo.R2 <- list()
list_var <- colnames(PREDICTRICE2)
list_var <- list_var[!list_var %in% c("Population_Francaise_Totale")]
for(variable in list_var){
  # RR <- c()
  # VV <- c()
  
  DATA_log <- cbind(PREDICTRICE2[variable],PREDICTRICE2[c("Population_Francaise_Totale")],PREDICTEUR2)
  
  "
  on veut sélectionner les variables le splus significative spour distinguer les individus entre eux.
  Les plus significatives au sens de la population totale
  "
  
  n <- names(PREDICTEUR2)
  
  f <- as.formula(paste(paste("as.matrix(cbind(",variable,",Population_Francaise_Totale-",variable,")) ~",sep=""),paste("",paste(n[!n %in% "(Intercept)"], collapse = " + "),sep = "")))
  
  model1.fit <- glm(f,data=DATA_log,family=binomial(link=logit))
  sum_model1 <- summary(model1.fit)
  sum_model1 <- as.data.frame(sum_model1$coefficients)
  sum_model1 <- sum_model1[order(sum_model1$`Pr(>|z|)`),]
  
  sum_modelk <- sum_model1
  
  while((sum_modelk[nrow(sum_modelk),4] > 0.05 && nrow(sum_modelk) >4) | (nrow(sum_modelk) >20)){
    pire <- Recup.pire.coef_log(sum_modelk)
    n <- n[!n %in% pire]
    f <- as.formula(paste(paste("as.matrix(cbind(",variable,",Population_Francaise_Totale-",variable,")) ~",sep=""),paste("",paste(n[!n %in% "(Intercept)"], collapse = " + "),sep = "")))
    
    modelk <- glm(f,data=DATA_log,family=binomial(link=logit))
    sum_modelk <- summary(modelk)
    #attributes(sum_modelk)
    #sum_modelk$null.deviance
    
    #RR <- c(RR,sum_modelk$) # on récupère le R2
    sum_modelk <- as.data.frame(sum_modelk$coefficients)
    sum_modelk <- sum_modelk[order(sum_modelk$`Pr(>|z|)`),]
    sum_modelk <- sum_modelk[!rownames(sum_modelk) %in% "(Intercept)",]
    # VV <- c(VV,nrow(sum_modelk)) # on récupère le nombre de variables
  }
  n <- names(as.data.frame(t(sum_modelk)))
  variables.explicatives_log[variable] <- as.data.frame(n)
  # evodf <- as.data.frame(cbind(VV,RR))
  # colnames(evodf) <- c("NBvariable","R2")
  # evo.R2[variable][[1]] <- evodf
}
```

```{r bootstrap_log2, echo=FALSE, fig.height=12, fig.width=18}
R2_hat_log <- NULL
REPET <- 500
for(tranche_age in 1:length(variables.explicatives_log)){
  # tranche_age <- 4
  population <- names(variables.explicatives_log)[tranche_age]
  var_pop <- as.character(variables.explicatives_log[[population]])
  DATA <- cbind(PREDICTRICE2[population],PREDICTRICE2["Population_Francaise_Totale"],PREDICTEUR2[,var_pop])
  
  R2_MC <- NULL
  f <- as.formula(paste(paste("as.matrix(cbind(",population,",Population_Francaise_Totale-",population,")) ~",sep=""),paste("",paste(var_pop[!var_pop %in% "(Intercept)"], collapse = " + "),sep = "")))
  for(ii in 1:REPET){
    ####### FOR ###
    train_index <- sample(1:nrow(DATA), round(0.8*nrow(DATA)))
    train <- as.data.frame((DATA[train_index,]))
    x_test <- as.matrix(PREDICTEUR2[-train_index,var_pop])
    y_test <- c(PREDICTRICE3[-train_index,population])
    colnames(test)[1] <- "Intercept"
    
    modelk <- glm(f,data=train,family=binomial(link=logit))
    # summary(modelk)
    
    # y_test <- PREDICTRICE3[[population]][train_index]
    
    prevision <- predict(modelk,as.data.frame(x_test),type="response")
    
    # ts.plot(y_test,col="forestgreen",ylim=c(0,1))
    # lines(prevision,col="tomato")
    
    new_R2 <- 1-sum((prevision-y_test)**2)/sum((mean(y_test)-y_test)**2)
    
    R2_MC <- c(R2_MC,new_R2)
  }
  R2_hat_log <- c(R2_hat_log,mean(R2_MC))

}
R2_hat_log <- data.frame(cbind(names(variables.explicatives_log),R2_hat_log))
colnames(R2_hat_log) <- c("Tranche de population","R2 ajusté")
```

<p style="text-align:justify;">Le R² obtenu par bootstrap 80% / 20% sur le modèle logistique.</p>
```{r affiche_bootstraped_log2, echo=FALSE, fig.height=12, fig.width=18}
R2_hat_log
```

```{r creer Data-Frame 22, echo=FALSE, fig.height=12, fig.width=18}
DFtrainLog <- list()
DFtestLog <- list()
popTotaleTrainLog <- list()
popTotaleTestLog <- list()
annees <- list(2013,2014,2015)
variablesReponseLog <- names(PREDICTRICE)[3:length(names(PREDICTRICE))]
nomPopTotaleLog <- variablesReponseLog[6]
variablesReponseLog <- variablesReponseLog[-6]
for(variableReponseLog in variablesReponseLog){
  variablesExpl <- as.character(variables.explicatives_log[[variableReponseLog]])
  minusAnnees<- as.vector(annees)
  for(annee in annees){
    nom <- paste(variableReponseLog, as.character(annee), sep="_")
    DFtrainLog[[nom]]<- cbind(PREDICTEUR[-which(PREDICTEUR$Annee %in% minusAnnees),variablesExpl],PREDICTRICE[-which(PREDICTEUR$Annee %in% minusAnnees),variableReponseLog])
    names(DFtrainLog[[nom]])[length(names(DFtrainLog[[nom]]))] <- variableReponseLog
    DFtestLog[[nom]]<- cbind(PREDICTEUR[which(PREDICTEUR$Annee == annee),variablesExpl],PREDICTRICE[which(PREDICTEUR$Annee == annee),variableReponseLog])
    names(DFtestLog[[nom]])[length(names(DFtestLog[[nom]]))] <- variableReponseLog
    minusAnnees <- minusAnnees[-c(1)]
  }
}
minusAnnees<- annees
for(annee in annees){
    popTotaleTrainLog[[as.character(annee)]] <- PREDICTRICE[-which(PREDICTRICE$Annee %in% minusAnnees),nomPopTotaleLog]
    popTotaleTestLog[[as.character(annee)]] <- PREDICTRICE[which(PREDICTRICE$Annee == annee),nomPopTotaleLog]
    minusAnnees <- minusAnnees[-c(1)]
 }
```


```{r, echo=FALSE, fig.height=12, fig.width=18}
modell <- list()
DF_repartition_Log <- list()

variableReponseLog <- variablesReponseLog[1]
for (annee in annees) {
  nom <- paste(variableReponseLog, as.character(annee), sep="_")
  DF_repartition_Log[[as.character(annee)]]<- DFtestLog[[nom]][variableReponseLog]
}

for(variableReponseLog in variablesReponseLog){
  
  
  
  for(annee in annees){
    nom <- paste(variableReponseLog, as.character(annee), sep="_")
    f <- as.formula(paste(paste("as.matrix(cbind(",DFtrainLog[[nom]][variableReponseLog],",popTotaleTrainLog[[as.character(annee)]]-",DFtrainLog[[nom]][variableReponseLog],")) ~",sep=""),".",sep = ""))
    modell[[nom]] <- glm(formula = f, data = DFtrainLog[[nom]], family=binomial(link = logit))
    prediction <- predict(modell[[nom]], DFtestLog[[nom]], type = "response")
    DFtestLog[[nom]] <- cbind(DFtestLog[[nom]],prediction)
    DF_repartition_Log[[as.character(annee)]]<-cbind(cbind(DF_repartition_Log[[as.character(annee)]],DFtestLog[[nom]][variableReponseLog]),as.data.frame(prediction))
    nem <- paste("prediction", variableReponseLog, sep = "_")
    colnames(DF_repartition_Log[[as.character(annee)]]) <- c(colnames(DF_repartition_Log[[as.character(annee)]])[1:(ncol(DF_repartition_Log[[as.character(annee)]])-1)],nem)
    }
}

for (annee in annees) {
  DF_repartition_Log[[as.character(annee)]]<-DF_repartition_Log[[as.character(annee)]][,2:ncol(DF_repartition_Log[[as.character(annee)]])] 
  DF_repartition_Log[[as.character(annee)]][c("popTotaleLog")] <- popTotaleTestLog[[as.character(annee)]]
  DF_repartition_Log[[as.character(annee)]][c("previsionTotale")] <- rowSums(DF_repartition_Log[[as.character(annee)]][c(2,4,6,8,10,12,14,16,18,20)])
  
} 
# summary(modell[[paste(variableReponseLog, as.character(annee), sep = "_")]])
# predict(modell[[paste(variableReponseLog, as.character(annee), sep = "_")]], DFtestLog[[nom]])

```

```{r, echo = FALSE, fig.height=12, fig.width=18}

for (annee in annees) {
  #Prévisions
  DF_repartition_Log[[as.character(annee)]][c(2,4,6,8,10,12,14,16,18,20)] <- DF_repartition_Log[[as.character(annee)]][c(2,4,6,8,10,12,14,16,18,20)]/DF_repartition_Log[[as.character(annee)]]$previsionTotale
  #Réel
    DF_repartition_Log[[as.character(annee)]][c(1,3,5,7,9,11,13,15,17,19)] <- DF_repartition_Log[[as.character(annee)]][c(1,3,5,7,9,11,13,15,17,19)]/DF_repartition_Log[[as.character(annee)]]$popTotaleLog
    DF_repartition_Log[[as.character(annee)]]$previsionTotale<-1
    DF_repartition_Log[[as.character(annee)]]$popTotaleLog<-1
}

plot(DF_repartition_Log[["2013"]]$Population_Feminine_0_19, xlab = "département", ylab = "proportion", col = "forestgreen")
points(DF_repartition_Log[["2013"]]$prediction_Population_Feminine_0_19, col = "red")
title( "Population féminine de 0 à 19 ans")
legend("topleft", pch = 1, col = c("forestgreen", "red"), c("réel", "prévu"))
```
<p style="text-align:justify;">De même que le modèle linéaire, le modèle logistique semble performant, voire plus.</p>


###Calcul des proportions :

<p style="text-align:justify;">Les proportions estimées avec le modèle logistique semblent bien plus proches des valeurs réelles que les estimations du modèle linéaire.</p>

```{r, echo = FALSE, fig.height=12, fig.width=18}
head(DF_repartition_Log[["2015"]])
```

###Calcul du R² total:

<p style="text-align:justify;">De nouveau le R² n'est pas impressionnant. C'est néanmoins le meilleur R² que nous ayons pu obtenir sur un modèle avec proportions. Nous pouvons retenir que plus nous rajoutons de variables, plus les prévisions seront de qualité. Nous avons retenu 20 variables, au vu des 1974 individus nous sommes tranquiles pour ne pas tomber dans un cas de surapprentissage.</p>


```{r, echo = FALSE, fig.height=12, fig.width=18}
moyenneLog <- list()
R2Log <- list()
for (annee in annees) {
  moyenneLog[[as.character(annee)]] <- colMeans(DF_repartition_Log[[as.character(annee)]])
  
  SCR <- 0
  for(groupe in c(1,3,5,7,9,11,13,15,17,19)){
    
    SCR <- SCR + sum((DF_repartition_Log[[as.character(annee)]][groupe]-DF_repartition_Log[[as.character(annee)]][groupe+1])**2)
    
  }

  SCT <- 0
  for(groupe in c(1,3,5,7,9,11,13,15,17,19)){
    
    SCT <- SCT + sum((DF_repartition_Log[[as.character(annee)]][groupe]-moyenneLog[[as.character(annee)]][groupe])**2)
    
  }

  R2Log[[as.character(annee)]] <- 1-SCR/SCT
} 

print(R2Log[[as.character(2015)]])

```